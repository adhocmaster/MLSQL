\documentclass[12pt]{article}
\renewcommand{\baselinestretch}{1}
\usepackage{fullpage}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm,verbatim,amssymb,amsfonts,amscd, graphicx, amsmath}
\usepackage{mathtools}
\usepackage{graphics}
\usepackage{relsize} %larger symbol fonts \mathlarger{}
\usepackage{mathrsfs} %mathscr font
\usepackage{fourier} %doublestruck
\usepackage{nccmath} %aligning equatinos as required
\usepackage{tikz} %drawing
\usetikzlibrary{backgrounds} %figure -- useful for framing
\usepackage{caption} %add caption to figure
\usepackage{float} %stopf "figure" from floating
\usepackage{pgfplots} %graphs
\usepackage{array, tabu}
\usepackage{scrextend} %margin indentation
\usepackage{algorithm} %algorithm
\usepackage[noend]{algpseudocode}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
%algorithm
\usepackage{cleveref}
%
\pgfplotsset{my style/.append style={axis x line=middle, axis y line= middle, xlabel={$v_k$}, ylabel={$y_k$}}}
\pgfplotsset{my style2/.append style={axis x line=middle, axis y line= middle, xlabel={$v$}, ylabel={$y$}}}
%%to fix quotes
\usepackage [autostyle, english = british]{csquotes}
\MakeOuterQuote{"}
%%

%%Bibliography
\usepackage[
    %backend=biber, 
    natbib=true,
    style=numeric,
    sorting=none
]{biblatex}
\addbibresource{cite.bib}
%%
\textheight23.0cm
\textwidth16.5cm
\footskip1.0cm



%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem*{surfacecor}{Corollary 1}
\newtheorem{conjecture}{Conjecture} 
\newtheorem{question}{Question} 
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}

\title{MLSQL: Machine Learning Meets SQL}
\author{V. Chakraborty and G. Muktadir}
\date{07 May, 2019}

\begin{document}
\maketitle
\section{Introduction}
There is a vast amount of data being generated through various applications around us -
sales data in a grocery store, inventory data in store houses, signal and imaging data in
various devices in medical facilities and so on. A lot of valuable information can be
harnessed from the data. Since access to data is no longer restricted only to big companies
and researchers, it is essential to develop tools which allow easy and proper extraction of
information from the data and thus can be used by those who do not have specific training
in developing programs for machine learning and handling data.


Statistical machine learning is extremely complex - models and algorithms in the field are
overwhelming and often not understandable for layman users. Making sensible and informed
decisions regarding trade-offs, parameters, hyper-parameters, optimisation, scalability,
and the like is quite impossible for these users. Existing systems, hardly make any effort
to help these users take advantage of machine learning.


The motivation behind MLSQL is to make machine learning accessible to a broad range of
users who work on small or large amounts of data. As the name suggests, the language
combines SQL and machine learning. With SQL like syntax, MLSQL provides a unified interface
to use data in SQL databases for machine learning purposes without having to change
applications or learn a new language. MLSQL is written in python and uses the SQL API.

\section{Related Work}
In this section we survey some platforms that offer similar features as ours. We note that
out work is not about exploiting machine learning to build a better query optimiser or data
mamangement services like in \cite{lohman2004} and \cite{ortiz18}. MLSQL enriches SQL by
adding machine learning features which can be used on the data being managed. 
Google BigQuery \cite{BigQuery} is a cloud based web service that makes querying massive
datasets less time consuming by enabling super-fast, SQL-like queries against append-only
tables \cite{Fernandes2015}. The use becomes simpler because users need not to have
knowledge, experience or management of the infrastructure. Our aim in this work is a
similar one. 

Microsoft's SQL server 2017 introduces some machine learning services using a Python-based
in-database Machine Learning Services \cite{SQLserver}. This is more aimed at python
developers and application builders. The desideratum is to make machine learning accessible
to domain independent SQL or SQL-like language users. Uber's Queryparser
\cite{QueryParser}, a tool for parsing and analyzing SQL queries.

\section{Design Decisions}
\subsection{Language Choice and Functionality}
We built MLSQL with \textit{Python 3}. Besides the recent popularty of Python3, we chose
the language because of the vast amount of libraries available for Python which offer
functions for complete support for machine learning. We chose \textit{SQLite3} to implement
the database and used the \textit{peewee} ORM. MLSQL explots Google's \textit{Tensor Flow}
through the \textit{Keras} open source machine learning library; \textit{scikit-learn}, a
free software machine learning library which offers classification, regression, support
vector machines, and the like; pytorch, another machine learning library based on the Torch
library.

\begin{figure}[H]
    \begin{center}
    \includegraphics[scale = 0.6]{initialpng.png}
    \caption{Execution flow in MLSQL}
    \end{center}
    \label{chart:execution}
\end{figure}


\subsection{Model Definitions}
There are two alternatives as far as placing the model and the database is concerned. If
the model definitions and the model is placed in the database (containing the training or
test data), it enhances portability; whereas, if the model is placed outside the database,
it provides more versatility in usage. We trade portability for versatility and place the
model definitions and the model outside the database (containing the training/testing
data).
\\
The meta-information of a new model is stored in a database, which is different from the
one containing the data, which can be called with any data of the user's choice. Thus,
although the user might have had a particular data set in mind whilst creating a model, she
can use it with any other data set, or the initial data set, but now, with alterations.
Thus MLSQL is highly dynamic, efficient, and easy to use.
%%%%%%%%%%%
\section{Language Specification}
MLSQL has the following data types
\begin{itemize}
    \item \texttt{ WORD } This is generally used to specify the name of model or a training profile.
    \item \texttt{ FLOAT } This is used to specify the training and the validation split of the datasets.
    \item \texttt{ INT } This is used to specify the number of epochs and the batch size.
    \item \texttt{ DELIMITER } The delimiter is semicolon (;)
    \item \texttt{ BOOL } This is used to specify if data should be shuffled or not.
    \item \texttt{ URL } This is used to specify the path of the database to be used for training or prediction.
    \item \texttt{FORMULA\_EXP} This is to specify a formula for the model.
\end{itemize}

It offers the following queries besides the usual SQL queries. The following is to create a training profile. The \texttt{VALIDATION\_SPLIT}, \texttt{BATCH\_SIZE}, \texttt{EPOCH}, \texttt{SHUFFLE} are optional attributes.

\begin{align*}
   \boxed{
        \texttt{ CREATE TRAINING\_PROFILE} \ \textcolor{blue}{ WORD } \texttt{ WITH } \textcolor{blue}{ SQL } \\
        \texttt{ AND VALIDATION\_SPLIT } \textcolor{blue}{ FLOAT } \texttt{ BATCH\_SIZE } \textcolor{blue}{INT} \texttt{ EPOCH } 
        \textcolor{blue}{ INT } \texttt{ SHUFFLE } \textcolor{blue}{ BOOL } \texttt{;}
        }
\end{align*}
To create an estimator, MLSQL has the following.
\begin{align*}
    & \texttt{CREATE ESTIMATOR } \textcolor{blue}{ WORD } \texttt{ TYPE } \textcolor{blue}{ WORD }\\
    & \texttt{ FORMULA } \textcolor{blue}{ FORMULA\_EXP } \texttt{ LOSS }
      \textcolor{blue}{ WORD } \texttt{ LEARNING\_RATE } FLOAT \texttt{ OPTIMIZER } \textcolor{blue}{WORD} \\
     & \texttt{ REGULARIZER } WORD \texttt{;}
\end{align*}
To actually train an estimator with a training profile, MLSQL has the following query.
\begin{align*}
    \texttt{ TRAIN } \textcolor{blue}{ WORD } \texttt{ WITH  TRAINING\_PROFILE } \textcolor{blue}{ WORD};
\end{align*}
To use a trained model to predict, MLSQL has provides the following
\begin{align*}
    \texttt{ PREDICT  WITH TRAINING\_PROFILE } \textcolor{blue}{ WORD } \texttt{ BY ESTIMATOR } 
    \textcolor{blue}{ WORD };
\end{align*}
and the database to be used can be specified thus
\begin{align*}
    \texttt{ USE } \textcolor{blue}{ URL } \texttt{; }
\end{align*}
\section{Creating And Training Estimators}
In order to understand the significance of the design choices and the functionality of the language, we will now provide an example. 
\subsection{Flowcharts}
\begin{figure}[H]
    \begin{center}
    \includegraphics[scale = 0.60]{train.png}
    \caption{Training in MLSQL}
    \label{chart:train}
    \end{center}
\end{figure}
\section{Future Work}


\printbibliography
\end{document}
